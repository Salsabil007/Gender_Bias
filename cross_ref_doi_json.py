from crossref.restful import Works
from crossref.restful import Journals
import requests
import json
import math
import pandas as pd
import numpy as np

##step one //this step runs multiple times. First time, I take 1k unique journals from top_25_single_issn.csv and extract their dois. Second time, I remove the first 1k from head 
##and take the 2nd 1k. 3rd time, I remove the first 2k journals and take the next 1k and so on.
'''def get_data(msg,issn):
    url = "https://api.crossref.org/journals/"+issn+"/works?select=DOI,published&cursor=*&mailto=support@crossref.org"
    res = requests.get(url)
    if res.status_code == 200:
        result = res.json()
        print(result['message']['total-results'])
        cnt = math.ceil(result['message']['total-results']/1000)
        print(cnt)
        
        a = "*"
        for i in range(cnt):
            url = "https://api.crossref.org/journals/"+issn+"/works?select=DOI,published&rows=1000&cursor="+a+"&mailto=support@crossref.org"
            res = requests.get(url)
            if res.status_code != 200:
                print("ohh no")
                return msg
            
            result = res.json()
            
            
            if 'message' in result:
                result['message']['issn'] = str(issn)
                msg.append(result['message'])

                if 'next-cursor' in result['message']:
                    a = result['message']['next-cursor']
                else:
                    return msg
                

            else:
                return msg

    else:
        return msg
    return msg


data = pd.read_csv("top_25_single_issn.csv")
doi = []
#data2 = data.drop_duplicates(subset=['journal'],keep="first")


n = 5500 
data = data.tail(data.shape[0]-n)
#data = data.head(500)

#print(data.tail(5))

issn = data['issn']
print("len of issn ",len(issn))

#exit(0)
#print("issn ",issn)


#remove = pd.read_csv("issn_doi.csv")
#remove = remove['issn'].unique()
#issn2 = [i for i in issn if i not in remove]

#print(len(issn))
#print(len(res))
#print(data['issn'].nunique())
#issn = res
#print(issn2)

count = 0
for i in issn:
    print("issn ",i)
    doi = get_data(doi,i)
    
    print("count ",count)
    count += 1
with open("doi_issn_json_6k2.json", "w") as outfile:
    json.dump(doi, outfile)'''


##step 2: I take the json generated by the step one and extract the doi, year etc from the json file and save it. It is also repeated several times, once for for each 1k journals.
'''with open('doi_issn_json_6k2.json', 'r') as openfile:
 
    # Reading from json file
    dx1 = json.load(openfile)

doi,issn,yr = [],[],[]

for i in dx1:
    #dx[0]['items'][0]['DOI']
    if 'items' in i:
        #print(i['items'])
        for j in i['items']:
            if 'published' in j:
                if 'date-parts' in j['published']:
                    if j['published']['date-parts'][0][0] < 2018:
                        continue

            if 'DOI' in j:
                doi.append(j['DOI'])
                if 'published' in j:
                    if 'date-parts' in j['published']:
                        yr.append(j['published']['date-parts'][0][0])
                    else:
                        yr.append(0)
                else:
                    yr.append(0)
                if 'issn' in i:
                    issn.append(i['issn'])
                else:
                    issn.append(0)
            else:
                continue
                
dummy = pd.DataFrame()
dummy['doi'] = doi
dummy['issn'] = issn
dummy['yr'] = yr
#dummy = dummy[dummy['yr'] >= 2018]

dummy.to_csv("doi_6k2_from_json.csv", index = False)'''




##step 3: I merge the data files generated by the second step.

data = pd.read_csv("doi_1k_from_json.csv")

tt = pd.read_csv("doi_2k_from_json.csv")
data = pd.concat([data, tt], ignore_index=True)

tt = pd.read_csv("doi_3k_from_json.csv")
data = pd.concat([data, tt], ignore_index=True)

tt = pd.read_csv("doi_4k_from_json.csv")
data = pd.concat([data, tt], ignore_index=True)

tt = pd.read_csv("doi_5k_from_json.csv")
data = pd.concat([data, tt], ignore_index=True)

tt = pd.read_csv("doi_6k1_from_json.csv")
data = pd.concat([data, tt], ignore_index=True)

tt = pd.read_csv("doi_6k2_from_json.csv")
data = pd.concat([data, tt], ignore_index=True)

data['issn'] = data['issn'].astype(str)
print(data.dtypes)

print(len(data))
print(data['issn'].nunique())
print(data['doi'].nunique())

data2 = pd.read_csv("top_25_issn.csv")

data2['issn'] = data2['issn'].str.lstrip('0')
data['issn'] = data['issn'].str.lstrip('0')
new = data.merge(data2, on = ['issn'],how='inner')

print(len(new))

new.to_csv("total_doi_crossref.csv", index = False)

